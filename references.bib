@Manual{R-knitr,
  title = {knitr: A General-Purpose Package for Dynamic Report Generation in R},
  author = {Yihui Xie},
  year = {2019},
  note = {R package version 1.25},
  url = {https://CRAN.R-project.org/package=knitr},
}
@Manual{R-papaja,
  title = {papaja: Prepare reproducible APA journal articles with R Markdown},
  author = {Frederik Aust and Marius Barth},
  year = {2019},
  note = {R package version 0.1.0.9842},
  url = {https://github.com/crsh/papaja},
}
@Manual{R-rstanarm,
  title = {rstanarm: Bayesian Applied Regression Modeling via Stan},
  author = {Jonah Gabry and Ben Goodrich},
  year = {2019},
  note = {R package version 2.19.2},
  url = {https://CRAN.R-project.org/package=rstanarm},
}
@Manual{R-tidyverse,
  title = {tidyverse: Easily Install and Load the 'Tidyverse'},
  author = {Hadley Wickham},
  year = {2017},
  note = {R package version 1.2.1},
  url = {https://CRAN.R-project.org/package=tidyverse},
}
@Article{EricksonBeginningBayes2017,
  title = {Beginning {{Bayes}}},
  volume = {39},
  copyright = {\textcopyright{} 2017 Teaching Statistics Trust},
  issn = {1467-9639},
  abstract = {Understanding a Bayesian perspective demands comfort with conditional probability and with probabilities that appear to change as we acquire additional information. This paper suggests a simple context in conditional probability that helps develop the understanding students would need for a successful introduction to Bayesian reasoning.},
  language = {en},
  number = {1},
  journal = {Teaching Statistics},
  doi = {10.1111/test.12121},
  author = {Tim Erickson},
  year = {2017},
  keywords = {statistics teaching,area diagrams,Bayes,conditional probability},
  pages = {30-35},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\T7N8BGDY\\Erickson - 2017 - Beginning Bayes.pdf;C\:\\Users\\wdnooy1\\Zotero\\storage\\K9U69H3X\\test.html},
}
@Book{CummingUnderstandingnewstatistics2012,
  address = {{New York}},
  title = {Understanding the New Statistics: {{Effect}} Sizes, Confidence Intervals, and Meta-Analysis},
  number = {Book, Whole},
  publisher = {{Routledge}},
  author = {Geoff Cumming},
  year = {2012},
  keywords = {Confidence intervals,meta analysis,Multivariate analysis,new statistics},
}
@Article{LevineQuantitativeCommunicationResearch2013,
  title = {Quantitative {{Communication Research}}: {{Review}}, {{Trends}}, and {{Critique}}},
  volume = {1},
  shorttitle = {Levine - 2013 - {{Quantitative Communication Research}}},
  abstract = {Trends in quantitative communication research are reviewed. A content analysis of 48 articles reporting original communication research published in 1988-1991 and 2008-2011 is reported. Survey research and self-report measurement remain common},
  language = {en},
  journal = {Review of Communication Research},
  doi = {10.12840},
  author = {Timothy R. Levine},
  year = {2013},
  keywords = {null hypothesis significance testing,NHST,criticisms},
  pages = {69-84},
  file = {C\:\\Users\\Wouter\\Dropbox\\Bibliography\\levine_2013_quantitative_communication_research_review_trends_and_critique.pdf;C\:\\Users\\wdnooy1\\Zotero\\storage\\K5ATMHBD\\Levine_-_2013_-_Quantitative_Communication_Research_Review_Trends_and_Critique.html},
}

@Article{LevineCriticalAssessmentNull2008,
  title = {A {{Critical Assessment}} of {{Null Hypothesis Significance Testing}} in {{Quantitative Communication Research}}},
  volume = {34},
  issn = {0360-3989},
  abstract = {Abstract.  Null hypothesis significance testing (NHST) is the most widely accepted and frequently used approach to statistical inference in quantitative communi},
  language = {en},
  number = {2},
  journal = {Human Communication Research},
  doi = {10.1111/j.1468-2958.2008.00317.x},
  author = {Timothy R. Levine and Ren{\a'e} Weber and Craig Hullett and Hee Sun Park and Lisa L. Massi Lindsey},
  month = {apr},
  year = {2008},
  pages = {171-187},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\CSB2TFQX\\Levine et al. - 2008 - A Critical Assessment of Null Hypothesis Significa.pdf;C\:\\Users\\wdnooy1\\Zotero\\storage\\4CYXDLAW\\4210725.html},
}
@Article{carverCaseStatisticalSignificance1993,
  title = {The {{Case}} against {{Statistical Significance Testing}}, {{Revisited}}},
  volume = {61},
  issn = {0022-0973},
  abstract = {At present, too many research results in education are blatantly described as significant, when they are in fact trivially small and unimportant. There are several things researchers can do to minimize the importance of statistical significance testing and get articles published without using these tests. First, they can insert statistically in front of significant in research reports. Second, results can be interpreted before p values are reported. Third, effect sizes can be reported along with measures of sampling error. Fourth, replication can be built into the design. The touting of insignificant results as significant because they are statistically significant is not likely to change until researchers break the stranglehold that statistical significance testing has on journal editors.},
  number = {4},
  journal = {The Journal of Experimental Education},
  author = {Ronald P. Carver},
  year = {1993},
  keywords = {hypothesis testing,Statistical Significance,Criticism},
  pages = {287-292},
  file = {C\:\\Users\\wdnooy1\\Dropbox\\Bibliography\\Carver1993.pdf},
}
@Article{carverCaseStatisticalSignificance1978,
  title = {The {{Case Against Statistical Significance Testing}}},
  volume = {48},
  issn = {0017-8055},
  abstract = {In recent years the use of traditional statistical methods in educational research has increasingly come under attack. In this article, Ronald P. Carver exposes the fantasies often entertained by researchers about the meaning of statistical significance. The author recommends abandoning all statistical significance testing and suggests other ways of evaluating research results. Carver concludes that we should return to the scientific method of examining data and replicating results rather than relying on statistical significance testing to provide equivalent information.},
  number = {3},
  journal = {Harvard Educational Review},
  doi = {10.17763/haer.48.3.t490261645281841},
  author = {Ronald Carver},
  month = {sep},
  year = {1978},
  keywords = {hypothesis testing,Statistical Significance,criticisms},
  pages = {378-399},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\4XPSC9UJ\\Carver - 1978 - The Case Against Statistical Significance Testing.pdf;C\:\\Users\\wdnooy1\\Zotero\\storage\\7KLWNUVQ\\haer.48.3.html},
}
@Article{tylerWhatStatisticalSignificance1931,
  title = {What {{Is Statistical Significance}}?},
  volume = {10},
  issn = {1555-4023},
  number = {5},
  journal = {Educational Research Bulletin},
  author = {Ralph W. Tyler},
  year = {1931},
  pages = {115-142},
  ids = {tylerWhatStatisticalSignificance1931a},
}
@Book{ziliakCultStatisticalSignificance2008,
  address = {{Ann Arbor, MI}},
  series = {Economics, Cognition, and Society},
  title = {The Cult of Statistical Significance : How the Standard Error Costs Us Jobs, Justice, and Lives},
  isbn = {0-472-07007-X},
  publisher = {{University of Michigan Press}},
  author = {Stephen Thomas Ziliak and Deirdre N. McCloskey},
  year = {2008},
  keywords = {significance testing,criticisms,Fisher; R.A (Ronald Aylmer); 1890-1962,Gosset; William Sealy; 1876-1937,Non-parametrische statistiek,Statistische betrouwbaarheid,Statistische toetsen,Wetenschapsbeleid},
}
@Book{morrisonSignificanceTestControversy1970,
  address = {{New York}},
  edition = {1},
  title = {The {{Significance Test Controversy}}: {{A Reader}}},
  isbn = {978-0-202-36888-7},
  shorttitle = {The {{Significance Test Controversy}}},
  abstract = {Tests of significance have been a key tool in the research kit of behavioral scientists for nearly fifty years, but their widespread and uncritical use has recently led to a rising volume of controversy about their usefulness. This book gathers the central papers in this continuing debate, brings the issues into clear focus, points out practical problems and philosophical pitfalls involved in using the tests, and provides a benchmark from which further analysis can proceed.The papers deal with some of the basic philosophy of science, mathematical and statistical assumptions connected with significance tests and the problems of the interpretation of test results, but the work is essentially non-technical in its emphasis. The collection succeeds in raising a variety of questions about the value of the tests; taken together, the questions present a strong case for vital reform in test use, if not for their total abandonment in research.The book is designed for practicing researchers-those not extensively trained in mathematics and statistics that must nevertheless regularly decide if and how tests of significance are to be used-and for those training for research. While controversy has been centered in sociology and psychology, and the book will be especially useful to researchers and students in those fields, its importance is great across the spectrum of the scientific disciplines in which statistical procedures are essential-notably political science, economics, and the other social sciences, education, and many biological fields as well.Denton E. Morrison is professor, Department of Sociology, Michigan State University. Ramon E. Henkel is associate professor emeritus, Department of Sociology University of Maryland. He teaches as part of the graduate faculty.},
  language = {en},
  publisher = {{Routledge}},
  author = {Denton E. Morrison and Ramon E. Henkel},
  year = {1970},
  keywords = {significance testing,Social Science / Sociology / General,Social Science / Methodology,Social Science / Research,criticism},
  googlebooks = {6w1MHjXxCO8C},
}
@Article{bakanTestSignificancePsychological1966,
  title = {The Test of Significance in Psychological Research},
  volume = {66},
  issn = {0033-2909},
  abstract = {The test of significance does not provide the information concerning psychological

phenomena characteristically attributed to it; and a great deal of mischief has been associated with its use. The basic logic associated with the test of significance is reviewed. The null hypothesis is characteristically false under any circumstances. Publication practices foster the reporting of small effects in populations. Psychologists have {"}adjusted{"} by misinterpretation, taking the p value as a {"}measure,{"} assuming that the test of significance provides automaticity of inference, and confusing the aggregate with the general. The difficulties are illuminated by bringing to bear the contributions from the decision-theory school on the Fisher approach. The Bayesian approach is suggested.},
  number = {6},
  journal = {Psychological Bulletin},
  author = {David Bakan},
  month = {dec},
  year = {1966},
  keywords = {Bayesian inference,significance testing,criticisms},
  pages = {423-437},
  file = {C\:\\Users\\wdnooy1\\Dropbox\\Bibliography\\Bakan1966.pdf},
}
@Article{depaoliImprovingTransparencyReplication2017,
  title = {Improving Transparency and Replication in {{Bayesian}} Statistics: {{The WAMBS}}-{{Checklist}}},
  volume = {22},
  issn = {1939-1463(Electronic),1082-989X(Print)},
  shorttitle = {Improving Transparency and Replication in {{Bayesian}} Statistics},
  abstract = {Bayesian statistical methods are slowly creeping into all fields of science and are becoming ever more popular in applied research. Although it is very attractive to use Bayesian statistics, our personal experience has led us to believe that naively applying Bayesian methods can be dangerous for at least 3 main reasons: the potential influence of priors, misinterpretation of Bayesian features and results, and improper reporting of Bayesian results. To deal with these 3 points of potential danger, we have developed a succinct checklist: the WAMBS-checklist (When to worry and how to Avoid the Misuse of Bayesian Statistics). The purpose of the questionnaire is to describe 10 main points that should be thoroughly checked when applying Bayesian analysis. We provide an account of ``when to worry'' for each of these issues related to: (a) issues to check before estimating the model, (b) issues to check after estimating the model but before interpreting results, (c) understanding the influence of priors, and (d) actions to take after interpreting results. To accompany these key points of concern, we will present diagnostic tools that can be used in conjunction with the development and assessment of a Bayesian model. We also include examples of how to interpret results when ``problems'' in estimation arise, as well as syntax and instructions for implementation. Our aim is to stress the importance of openness and transparency of all aspects of Bayesian estimation, and it is our hope that the WAMBS questionnaire can aid in this process. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  number = {2},
  journal = {Psychological Methods},
  doi = {10.1037/met0000065},
  author = {Sarah Depaoli and Rens {van de Schoot}},
  year = {2017},
  keywords = {Methodology,Bayesian analysis,Statistical Probability,Experimental Replication,Statistical Estimation,Estimation checks},
  pages = {240-261},
  file = {C\:\\Users\\wdnooy1\\Dropbox\\Bibliography\\DepaoliVandeSchoot2017.pdf;C\:\\Users\\wdnooy1\\Zotero\\storage\\M97UX6SR\\2015-57469-001.html},
}
@Article{kruschkeBayesianAssessmentNull2011,
  title = {Bayesian {{Assessment}} of {{Null Values Via Parameter Estimation}} and {{Model Comparison}}},
  volume = {6},
  issn = {1745-6916},
  abstract = {Psychologists have been trained to do data analysis by asking whether null values can be rejected. Is the difference between groups nonzero? Is choice accuracy not at chance level? These questions have been traditionally addressed by null hypothesis significance testing (NHST). NHST has deep problems that are solved by Bayesian data analysis. As psychologists transition to Bayesian data analysis, it is natural to ask how Bayesian analysis assesses null values. The article explains and evaluates two different Bayesian approaches. One method involves Bayesian model comparison (and uses Bayes factors). The second method involves Bayesian parameter estimation and assesses whether the null value falls among the most credible values. Which method to use depends on the specific question that the analyst wants to answer, but typically the estimation approach (not using Bayes factors) provides richer information than the model comparison approach.},
  language = {en},
  number = {3},
  journal = {Perspectives on Psychological Science},
  doi = {10.1177/1745691611406925},
  author = {John K. Kruschke},
  month = {may},
  year = {2011},
  keywords = {Bayesian analysis,significance testing},
  pages = {299-312},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\APULMRX8\\Kruschke - 2011 - Bayesian Assessment of Null Values Via Parameter E.pdf},
}
@Book{JamesIntroductionStatisticalLearning2017,
  address = {{New York}},
  edition = {1st ed. 2013, Corr. 7th printing 2017 edition},
  title = {An {{Introduction}} to {{Statistical Learning}}: With {{Applications}} in {{R}}},
  isbn = {978-1-4614-7137-0},
  shorttitle = {An {{Introduction}} to {{Statistical Learning}}},
  abstract = {An Introduction to Statistical Learning provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance to marketing to astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, and more. Color graphics and real-world examples are used to illustrate the methods presented. Since the goal of this textbook is to facilitate the use of these statistical learning techniques by practitioners in science, industry, and other fields, each chapter contains a tutorial on implementing the analyses and methods presented in R, an extremely popular open source statistical software platform.Two of the authors co-wrote The Elements of Statistical Learning (Hastie, Tibshirani and Friedman, 2nd edition 2009), a popular reference book for statistics and machine learning researchers. An Introduction to Statistical Learning covers many of the same topics, but at a level accessible to a much broader audience. This book is targeted at statisticians and non-statisticians alike who wish to use cutting-edge statistical learning techniques to analyze their data. The text assumes only a previous course in linear regression and no knowledge of matrix algebra.},
  language = {English},
  publisher = {{Springer}},
  author = {Gareth James and Daniela Witten and Trevor Hastie and Robert Tibshirani},
  month = {sep},
  year = {2017},
  keywords = {statistical inference,introduction,machine learning},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\JU2Z2TMW\\James et al. - 2017 - An Introduction to Statistical Learning with Appl.pdf},
}
@Book{efronComputerAgeStatistical2016,
  address = {{New York, NY}},
  edition = {1 edition},
  title = {Computer {{Age Statistical Inference}}: {{Algorithms}}, {{Evidence}}, and {{Data Science}}},
  isbn = {978-1-107-14989-2},
  shorttitle = {Computer {{Age Statistical Inference}}},
  abstract = {The twenty-first century has seen a breathtaking expansion of statistical methodology, both in scope and in influence. 'Big data', 'data science', and 'machine learning' have become familiar terms in the news, as statistical methods are brought to bear upon the enormous data sets of modern science and commerce. How did we get here? And where are we going? This book takes us on an exhilarating journey through the revolution in data analysis following the introduction of electronic computation in the 1950s. Beginning with classical inferential theories - Bayesian, frequentist, Fisherian - individual chapters take up a series of influential topics: survival analysis, logistic regression, empirical Bayes, the jackknife and bootstrap, random forests, neural networks, Markov chain Monte Carlo, inference after model selection, and dozens more. The distinctly modern approach integrates methodology and algorithms with statistical inference. The book ends with speculation on the future direction of statistics and data science.},
  language = {English},
  publisher = {{Cambridge University Press}},
  author = {Bradley Efron and Trevor Hastie},
  month = {jul},
  year = {2016},
  keywords = {Bayesian analysis,statistical inference,prediction,cross-validation},
  note = {boek in bezit},
}
@Article{kassBayesFactors1995,
  title = {Bayes {{Factors}}},
  volume = {90},
  issn = {0162-1459},
  abstract = {In a 1935 paper and in his book Theory of probability, Jeffresy developed a methodology for quantifying the evidence in favor of a scientific theory. The centerpies was a number, now called the Bayes factor, which is the posterior odds of the null hypothesis when the prior probability on the null is one-half. Although there has been much discussion of Bayesian hypothesis testing in the context of criticism of P-values, less attention has been given to the Bayes as a practical tool of applied statistics. In this article we review and discuss the uses of Bayes factors in the context of five scientific applications in genetics, sports, ecology, sociology, and psychology. We emphasize the following points: From Jeffrey's Bayesian viewpoint, the purpose of hypothesis testing is to evaluate the evidence in favor of a scientific theory. Bayes factors offer a way of evaluating evidence in favor of a null hypothesis. Bayes factors provide a way of incorporating external information into the evaluation of evidence about a hypothesis. Bayes factors are very general and do not require alternative models to be nested. Several techniques are available for computing Bayes factors, including asymptotic approximations that are easy to compute using the output from standard packages that maximize likelihoods. In {"}non-Bayesian significance tests. The Schwarz criterion (or BIC) gives a rough approximation to the logarithm of the Bayes factor, which is easy to use and does not require evaluation of prior distributions. When one is interested in estimation or prediction, Bayes factors may be converted to weights to be attached to various models so that a composite estimate or prediction may be obtained that takes account of structural or model uncertainty. Algorithms have been proposed that allow model uncertainty to be taken into account when the class of models initially considered is very large. Bayes factors are useful for guiding an evolutionary model-building process. It is important, and feasible, to assess the sensitivity of conclusions to the prior distributions used.},
  number = {430},
  journal = {Journal of the American Statistical Association},
  doi = {10.2307/2291091},
  author = {Robert E. Kass and Adrian E. Raftery},
  year = {1995},
  keywords = {Bayes factors},
  pages = {773-795},
  file = {C\:\\Users\\wdnooy1\\Dropbox\\Bibliography\\KassRaftery1995.pdf},
}
@Book{McElreathStatisticalRethinkingBayesian2015,
  address = {{Boca Raton}},
  title = {Statistical {{Rethinking}}: {{A Bayesian Course}} with {{Examples}} in {{R}} and {{Stan}}},
  number = {Book, Whole},
  publisher = {{CRC Press}},
  author = {Richard McElreath},
  year = {2015},
  keywords = {stan,Bayesian statistics},
}
@Book{GelmanBayesianDataAnalysis2013,
  title = {Bayesian {{Data Analysis}}, {{Third Edition}}},
  isbn = {978-1-4398-4095-5},
  abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors\textemdash{}all leaders in the statistics community\textemdash{}introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book's web page.},
  language = {en},
  publisher = {{CRC Press}},
  author = {Andrew Gelman and John B. Carlin and Hal S. Stern and David B. Dunson and Aki Vehtari and Donald B. Rubin},
  month = {nov},
  year = {2013},
  keywords = {Mathematics / Probability \& Statistics / General,Computers / Mathematical \& Statistical Software,Psychology / Research \& Methodology},
  googlebooks = {ZXL6AQAAQBAJ},
}
@Article{TQMP14-2-99,
  title = {User-Friendly {{Bayesian}} Regression Modeling: {{A}} Tutorial with Rstanarm and Shinystan},
  volume = {14},
  abstract = {This tutorial provides a pragmatic introduction to specifying, estimating and interpreting single-level and hierarchical linear regression models in the Bayesian framework. We start by summarizing why one should consider the Bayesian approach to the most common forms of regression. Next we introduce the R package rstanarm for Bayesian applied regression modeling. An overview of rstanarm fundamentals accompanies step-by-step guidance for fitting a single-level regression model with the stan\textsubscript{g}lm function, and fitting hierarchical regression models with the stan\textsubscript{l}mer function, illustrated with data from an experience sampling study on changes in affective states. Exploration of the results is facilitated by the intuitive and user-friendly shinystan package. Data and scripts are available on the Open Science Framework page of the project. For readers unfamiliar with R, this tutorial is self-contained to enable all researchers who apply regression techniques to try these methods with their own data. Regression modeling with the functions in the rstanarm package will be a straightforward transition for researchers familiar with their frequentist counterparts, lm (or glm) and lmer.},
  number = {2},
  journal = {The Quantitative Methods for Psychology},
  doi = {10.20982/tqmp.14.2.p099},
  author = {Chelsea Muth and Zita Oravecz and Jonah Gabry},
  year = {2018},
  keywords = {rstan,rstanarm},
  pages = {99-119},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\CMU42HLI\\MuthOraveczGabry2018.pdf},
  publisher = {TQMP},
}
@InProceedings{MadanSocialsensingepidemiological2010,
  title = {Social Sensing for Epidemiological Behavior Change},
  isbn = {978-1-60558-843-8},
  abstract = {An important question in behavioral epidemiology and public health is to understand how individual behavior is affected by illness and stress. Although changes in individual behavior are intertwined with contagion, epidemiologists today do not have sensing or modeling tools to quantitatively measure its effects in real-world conditions. In this paper, we propose a novel application of ubiquitous computing. We use mobile phone based co-location and communication sensing to measure characteristic behavior changes in symptomatic individuals, reflected in their total communication, interactions with respect to time of day (e.g., late night, early morning), diversity and entropy of face-to-face interactions and movement. Using these extracted mobile features, it is possible to predict the health status of an individual, without having actual health measurements from the subject. Finally, we estimate the temporal information flux and implied causality between physical symptoms, behavior and mental health.},
  booktitle = {Proceedings of the 12th {{ACM}} International Conference on {{Ubiquitous}} Computing},
  publisher = {{ACM}},
  author = {Anmol Madan and Manuel Cebrian and David Lazer and Alex Pentland},
  editor = {Jakob E. Bardram and Marc Langheinrich and Khai N. Truong and Paddy Nixon},
  year = {2010},
  pages = {291-300},
  note = {Conference Proceedings},
}
@Misc{magnussonUsingLmeLmer2015,
  title = {Using {{R}} and Lme/Lmer to Fit Different Two- and Three-Level Longitudinal Models - {{R Psychologist}}},
  abstract = {I often get asked about how to fit different longitudinal models in lme/lmer. In this post I cover several different two-level, three-level and partially nested models.},
  language = {en},
  journal = {R Psychologist},
  author = {Kristoffer Magnusson},
  month = {apr},
  year = {2015},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\JELSQQRL\\r-guide-longitudinal-lme-lmer.html},
}
@Article{WagenmakersAICmodelselection2004,
  title = {{{AIC}} Model Selection Using {{Akaike}} Weights},
  volume = {11},
  issn = {1069-9384, 1531-5320},
  abstract = {The Akaike information criterion (AIC; Akaike, 1973) is a popular method for comparing the adequacy of multiple, possibly nonnested models. Current practice in cognitive psychology is to accept a single model on the basis of only the ``raw'' AIC values, making it difficult to unambiguously interpret the observed AIC differences in terms of a continuous measure such as probability. Here we demonstrate that AIC values can be easily transformed to so-called Akaike weights (e.g., Akaike, 1978, 1979; Bozdogan, 1987; Burnham \& Anderson, 2002), which can be directly interpreted as conditional probabilities for each model. We show by example how these Akaike weights can greatly facilitate the interpretation of the results of AIC model comparison procedures.},
  language = {en},
  number = {1},
  journal = {Psychonomic Bulletin \& Review},
  doi = {10.3758/BF03206482},
  author = {Eric-Jan Wagenmakers and Simon Farrell},
  month = {feb},
  year = {2004},
  keywords = {Akaike weights},
  pages = {192-196},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\5JQIENPQ\\Wagenmakers and Farrell - 2004 - AIC model selection using Akaike weights.pdf;C\:\\Users\\wdnooy1\\Zotero\\storage\\YJWUIR33\\BF03206482.html},
}

@Article{BurnhamKullbackLeiblerinformationbasis2001,
  title = {Kullback-{{Leibler}} Information as a Basis for Strong Inference in Ecological Studies},
  volume = {28},
  issn = {1448-5494},
  abstract = {We describe an information-theoretic paradigm for analysis of ecological data, based on Kullback\textendash{}Leibler information, that is an extension of likelihood theory and avoids the pitfalls of null hypothesis testing. Information-theoretic approaches emphasise a deliberate focus on the a priori science in developing a set of multiple working hypotheses or models. Simple methods then allow these hypotheses (models) to be ranked from best to worst and scaled to reflect a strength of evidence using the likelihood of each model (gi), given the data and the models in the set (i.e. L(gi | data)). In addition, a variance component due to model-selection uncertainty is included in estimates of precision. There are many cases where formal inference can be based on all the models in the a priori set and this multi-model inference represents a powerful, new approach to valid inference. Finally, we strongly recommend inferences based on a priori considerations be carefully separated from those resulting from some form of data dredging. An example is given for questions related to age- and sex-dependent rates of tag loss in elephant seals (Mirounga leonina).},
  language = {en},
  number = {2},
  journal = {Wildlife Research},
  doi = {10.1071/wr99107},
  author = {Kenneth P. Burnham and David R. Anderson},
  year = {2001},
  keywords = {Akaike weights},
  pages = {111-119},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\UVSA6EAI\\Burnham and Anderson - 2001 - Kullback-Leibler information as a basis for strong.pdf;C\:\\Users\\wdnooy1\\Zotero\\storage\\QW448NVE\\WR99107.html},
}
@InProceedings{AkaikeInformationtheoryextension1973,
  address = {{Budapest}},
  title = {Information Theory and an Extension of the Maximum Likelihood Principle},
  booktitle = {2nd {{International Symposium}} on {{Information Theory}}, {{Tsahkadsor}}, {{Armenia}}, {{USSR}}, Eptember 2-8, 1971},
  publisher = {{Akad{\'e}miai Kiad{\'o}}},
  author = {Hirotuge Akaike},
  editor = {B.N. Petrov and F. Cs{\a'a}ki},
  year = {1973},
  pages = {267--281},
}

@Article{akaikeNewLookStatistical1974,
  title = {A New Look at the Statistical Model Identification},
  volume = {19},
  issn = {0018-9286},
  abstract = {For purposes of model identification, the author proposes the statistic AIC=-2log(maximum likelihood)+2 (number of independently adjusted parameters within the model). In multiple decision problems the model minimizing the statistic AIC among all possible models is chosen. A suitable modification of AIC for easy computer calculation in time series analysis is given. The method is illustrated by numerical examples.},
  number = {6},
  journal = {Institute of Electrical and Electronics Engineers. Transactions on Automatic Control},
  doi = {https://doi.org/10.1109\%2FTAC.1974.1100705},
  author = {Hirotugu Akaike},
  year = {1974},
  pages = {716--723},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\47UQWQQ3\\mathscinet-getitem.html},
  mrnumber = {0423716},
}
@Article{WatanabeAsymptoticEquivalenceBayes2010,
  title = {Asymptotic {{Equivalence}} of {{Bayes Cross Validation}} and {{Widely Applicable Information Criterion}} in {{Singular Learning Theory}}},
  volume = {11},
  issn = {ISSN 1533-7928},
  abstract = {In regular statistical models, the leave-one-out cross-validation is asymptotically equivalent to the Akaike information criterion. However, since many learning machines are singular statistical models, the asymptotic behavior of the cross-validation remains unknown. In previous studies, we established the singular learning theory and proposed a widely applicable information criterion, the expectation value of which is asymptotically equal to the average Bayes generalization loss. In the present paper, we theoretically compare the Bayes cross-validation loss and the widely applicable information criterion and prove two theorems. First, the Bayes cross-validation loss is asymptotically equivalent to the widely applicable information criterion as a random variable. Therefore, model selection and hyperparameter optimization using these two values are asymptotically equivalent. Second, the sum of the Bayes generalization error and the Bayes cross-validation error is asymptotically equal to 2{$\lambda$}/n, where {$\lambda$} is the real log canonical threshold and n is the number of training samples. Therefore the relation between the cross-validation error and the generalization error is determined by the algebraic geometrical structure of a learning machine. We also clarify that the deviance information criteria are different from the Bayes cross-validation and the widely applicable information criterion.},
  number = {Dec},
  journal = {Journal of Machine Learning Research},
  author = {Sumio Watanabe},
  year = {2010},
  keywords = {WAIC},
  pages = {3571-3594},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\P5VXUDPZ\\Watanabe - 2010 - Asymptotic Equivalence of Bayes Cross Validation a.pdf;C\:\\Users\\wdnooy1\\Zotero\\storage\\PU3AP2TZ\\watanabe10a.html},
}
@Article{Vehtari2017,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  volume = {27},
  issn = {1573-1375},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  number = {5},
  journal = {Statistics and Computing},
  doi = {10.1007/s11222-016-9696-4},
  author = {Aki Vehtari and Andrew Gelman and Jonah Gabry},
  month = {sep},
  year = {2017},
  pages = {1413-1432},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\IDJGDXVL\\VehtariGelmanGabry2017.pdf},
  day = {01},
}
@Article{YaoUsingStackingAverage2018,
  title = {Using {{Stacking}} to {{Average Bayesian Predictive Distributions}}},
  issn = {1936-0975, 1931-6690},
  abstract = {Bayesian model averaging is flawed in the MM{$<$}math alttext={"}\$\textbackslash{}mathcal\{M\}\${"} overflow={"}scroll{"}{$><$}mi mathvariant={"}script{"}{$>$}M{$<$}/mi{$><$}/math{$>$}-open setting in which the true data-generating process is not one of the candidate models being fit. We take the idea of stacking from the point estimation literature and generalize to the combination of predictive distributions. We extend the utility function to any proper scoring rule and use Pareto smoothed importance sampling to efficiently compute the required leave-one-out posterior distributions. We compare stacking of predictive distributions to several alternatives: stacking of means, Bayesian model averaging (BMA), Pseudo-BMA, and a variant of Pseudo-BMA that is stabilized using the Bayesian bootstrap. Based on simulations and real-data applications, we recommend stacking of predictive distributions, with bootstrapped-Pseudo-BMA as an approximate alternative when computation cost is an issue.},
  language = {EN},
  journal = {Bayesian Analysis},
  doi = {10.1214/17-BA1091},
  author = {Yuling Yao and Aki Vehtari and Daniel Simpson and Andrew Gelman},
  year = {2018},
  keywords = {Stan,Bayesian model averaging,model combination,predictive distribution,proper scoring rule,stacking},
  file = {C\:\\Users\\wdnooy1\\Zotero\\storage\\I9P8HVKX\\1516093227.html},
}
@TechReport{ClarkBayesianBasicsConceptual2014,
  title = {Bayesian {{Basics}}. {{A Conceptual Introduction}} with {{Application}} in {{R}} and {{Stan}}},
  institution = {{Center for Statistical Consultation and Research, University of Michigan}},
  author = {Michael Clark},
  year = {2014},
  keywords = {Bayesian statistics},
  note = {Report},
}

@Book{BerryStatisticsBayesianPerspective1996,
  address = {{Belmont, CA}},
  title = {Statistics: {{A Bayesian Perspective}}},
  isbn = {978-0-534-23472-0},
  shorttitle = {Statistics},
  abstract = {Statistics: A Bayesian Perspective is a general introductory test that only assumes familiarity with college algebra and offers the following significant features: it is the only introductory textbook based on Bayesian ideas, it combines concepts and methods, it presents statistics as a means of integrating data into the scientific process, it develops ideas through uncommonly interesting and real-world examples, it introduces, early on, ideas of data analysis and experimental design, and it includes a data disk that also contains Minitab macros specifically useful for calculations.},
  language = {en},
  publisher = {{Duxbury Press}},
  author = {Donald A. Berry},
  year = {1996},
  keywords = {Mathematics / Probability \& Statistics / General},
  googlebooks = {thKMQgAACAAJ},
}

@Book{lambertStudentsGuideBayesian2018,
  address = {{Los Angeles}},
  edition = {1 edition},
  title = {A {{Students Guide}} to {{Bayesian Statistics}}},
  isbn = {978-1-4739-1636-4},
  abstract = {Supported by a wealth of learning features, exercises, and visual elements as well as online video tutorials and interactive simulations, this book is the first student-focused introduction to Bayesian statistics.  Without sacrificing technical integrity for the sake of simplicity, the author draws upon accessible, student-friendly language to provide approachable instruction perfectly aimed at statistics and Bayesian newcomers. Through a logical structure that introduces and builds upon key concepts in a gradual way and slowly acclimatizes~students to using R and Stan software, the book covers:  An introduction to probability and Bayesian inference Understanding Bayes' rule~ Nuts and bolts of Bayesian analytic methods Computational Bayes and real-world Bayesian analysis Regression analysis and hierarchical methods  This unique guide will help students develop the statistical confidence and skills to put the Bayesian formula into practice, from the basic concepts of statistical inference to complex applications of analyses.},
  language = {English},
  publisher = {{SAGE Publications Ltd}},
  author = {Ben Lambert},
  month = {may},
  year = {2018},
  keywords = {introduction,Bayesian data analysis},
}

@Book{kurtBayesianStatisticsFun2019,
  address = {{San Francisco}},
  title = {Bayesian {{Statistics}} the {{Fun Way}}},
  isbn = {978-1-59327-956-1},
  abstract = {Many professionals use statistics and probabilities in their everyday work but struggle to make much sense of what they're doing. Bayesian Statistics the Fun Way gets you understanding the theory behind data analysis without making you slog through a load of dry concepts first - with no programming experience necessary.Fun and unusual examples are used to illustrate otherwise dry statistical concepts. You'll learn about probability with LEGO, statistics through Star Wars, distributions with bomb fuses, estimation through precipitation, and come away with some strong mathematical reasoning skills. You'll start with learning about priors and calculating simple probabilities and move on to measuring spreads and distributions, modelling data, simulating monte carlo scenarios, handling irrational data; you'll even get a crash course in R basics.This is a super approachable book for people who need to do data science and probability work in their lives, but never got a good grip on the underlying theory.},
  language = {English},
  publisher = {{No Starch Press}},
  author = {Will Kurt},
  month = {jul},
  year = {2019},
  keywords = {introduction,Bayesian data analysis},
}

@Book{leeBayesianStatisticsIntroduction2012,
  address = {{Chichester, West Sussex ; Hoboken, N.J}},
  edition = {4th edition},
  title = {Bayesian {{Statistics}}: {{An Introduction}}, 4th {{Edition}}: {{An Introduction}}, 4th {{Edition}}},
  isbn = {978-1-118-33257-3},
  shorttitle = {Bayesian {{Statistics}}},
  abstract = {Bayesian Statistics is the school of thought that combines prior beliefs with the likelihood of a hypothesis to arrive at posterior beliefs. The first edition of Peter Lee s book appeared in 1989, but the subject has moved ever onwards, with increasing emphasis on Monte Carlo based techniques. This new fourth edition looks at recent techniques such as variational methods, Bayesian importance sampling, approximate Bayesian computation and Reversible Jump Markov Chain Monte Carlo (RJMCMC), providing a concise account of the way in which the Bayesian approach to statistics develops as well as how it contrasts with the conventional approach. The theory is built up step by step, and important notions such as sufficiency are brought out of a discussion of the salient features of specific examples. This edition: * Includes expanded coverage of Gibbs sampling, including more numerical examples and treatments of OpenBUGS, R2WinBUGS and R2OpenBUGS. * Presents significant new material on recent techniques such as Bayesian importance sampling, variational Bayes, Approximate Bayesian Computation (ABC) and Reversible Jump Markov Chain Monte Carlo (RJMCMC). * Provides extensive examples throughout the book to complement the theory presented. * Accompanied by a supporting website featuring new material and solutions. More and more students are realizing that they need to learn Bayesian statistics to meet their academic and professional goals. This book is best suited for use as a main text in courses on Bayesian statistics for third and fourth year undergraduates and postgraduate students.},
  language = {English},
  publisher = {{Wiley}},
  author = {Peter M. Lee},
  month = {sep},
  year = {2012},
  keywords = {introduction,Bayesian data analysis},
}
